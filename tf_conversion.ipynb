{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/frogermcs/TFLite-Tester/blob/master/notebooks/Testing_TFLite_model.ipynb#scrollTo=H0j5p4zf0S2i\n",
        "\n",
        "\n",
        "https://colab.research.google.com/drive/1XEBcXPaS27t9PG301jJzFnU_KouAfjKk?usp=sharing#scrollTo=K2HBbMY9G4Q5"
      ],
      "metadata": {
        "id": "kHnBn4P1HLtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:deadsnakes/ppa\n",
        "!sudo apt-get -y update\n",
        "!sudo apt-get -y install python3.9\n",
        "!sudo apt-get -y install python3.9-dev\n",
        "!sudo apt-get -y install python3-pip\n",
        "!sudo apt-get -y install python3.9-distutils\n",
        "!python3.9 -m pip install -U setuptools \\\n",
        "  && python3.9 -m pip install -U pip \\\n",
        "  && python3.9 -m pip install -U distlib\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "!python3.9 -m pip install tensorflow==2.10.0 \\\n",
        "  && python3.9 -m pip install -U onnx \\\n",
        "  && python3.9 -m pip install -U nvidia-pyindex \\\n",
        "  && python3.9 -m pip install -U onnx-graphsurgeon \\\n",
        "  && python3.9 -m pip install -U onnxsim \\\n",
        "  && python3.9 -m pip install -U simple_onnx_processing_tools \\\n",
        "  && python3.9 -m pip install -U onnx2tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfk_DnC8Al0W",
        "outputId": "80533b60-7153-4029-aa00-ca1e2b21bd6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [1 InRelease 3,622\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Waiting for heade\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r0% [3 InRelease 14.2 kB/114 kB 12%] [Connecting to security.ubuntu.com (185.125\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,014 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,310 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,015 kB]\n",
            "Hit:17 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,539 kB]\n",
            "Fetched 8,218 kB in 2s (4,075 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:8 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.9 is already the newest version (3.9.16-1+focal1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.9-dev is already the newest version (3.9.16-1+focal1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n",
            "Fetched 2,389 kB in 0s (5,547 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 128275 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.9-distutils'\n",
            "python3-distutils is already the newest version (3.8.10-0ubuntu1~20.04).\n",
            "python3-distutils set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-67.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting distlib\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib\n",
            "Successfully installed distlib-0.3.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mupdate-alternatives: error: alternative path /usr/bin/python3.7 doesn't exist\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (23.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (0.31.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.51.3)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.15.0)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (4.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.15.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (23.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.22.4)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (15.0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (67.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
            "Installing collected packages: keras, tensorflow-estimator, keras-preprocessing, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "Successfully installed keras-2.10.0 keras-preprocessing-1.1.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.1 protobuf-3.20.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=ce20dff464a4e55c6c02a60f8e45cb86171658a7807b3d6e2cacea14f1e460fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/63/71/c50214b560fa8c319598c2de3c1616f6d68e1d2c7f17a5e82d\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting onnx-graphsurgeon\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.26-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from onnx-graphsurgeon) (1.22.4)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (from onnx-graphsurgeon) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx->onnx-graphsurgeon) (4.5.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx->onnx-graphsurgeon) (3.20.3)\n",
            "Installing collected packages: onnx-graphsurgeon\n",
            "Successfully installed onnx-graphsurgeon-0.3.26\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.3.2-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (from onnxsim) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxsim) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxsim) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx->onnxsim) (3.20.3)\n",
            "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pygments, mdurl, markdown-it-py, rich, onnxsim\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed markdown-it-py-2.2.0 mdurl-0.1.2 onnxsim-0.4.17 pygments-2.14.0 rich-13.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting simple_onnx_processing_tools\n",
            "  Downloading simple_onnx_processing_tools-1.1.16-py3-none-any.whl (7.7 kB)\n",
            "Collecting sor4onnx>=1.0.5\n",
            "  Downloading sor4onnx-1.0.5-py3-none-any.whl (7.1 kB)\n",
            "Collecting soa4onnx>=1.0.3\n",
            "  Downloading soa4onnx-1.0.3-py3-none-any.whl (6.1 kB)\n",
            "Collecting sio4onnx>=1.0.2\n",
            "  Downloading sio4onnx-1.0.2-py3-none-any.whl (6.9 kB)\n",
            "Collecting sit4onnx>=1.0.6\n",
            "  Downloading sit4onnx-1.0.6-py3-none-any.whl (9.8 kB)\n",
            "Collecting sog4onnx>=1.0.15\n",
            "  Downloading sog4onnx-1.0.15-py3-none-any.whl (9.2 kB)\n",
            "Collecting sng4onnx>=1.0.1\n",
            "  Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n",
            "Collecting scc4onnx>=1.0.5\n",
            "  Downloading scc4onnx-1.0.5-py3-none-any.whl (9.4 kB)\n",
            "Collecting sed4onnx>=1.0.5\n",
            "  Downloading sed4onnx-1.0.5-py3-none-any.whl (5.7 kB)\n",
            "Collecting snd4onnx>=1.1.6\n",
            "  Downloading snd4onnx-1.1.6-py3-none-any.whl (9.0 kB)\n",
            "Collecting ssi4onnx>=1.0.2\n",
            "  Downloading ssi4onnx-1.0.2-py3-none-any.whl (5.5 kB)\n",
            "Collecting ssc4onnx>=1.0.4\n",
            "  Downloading ssc4onnx-1.0.4-py3-none-any.whl (6.8 kB)\n",
            "Collecting sod4onnx>=1.0.0\n",
            "  Downloading sod4onnx-1.0.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting onnx2json>=2.0.4\n",
            "  Downloading onnx2json-2.0.4-py3-none-any.whl (5.0 kB)\n",
            "Collecting soc4onnx>=1.0.2\n",
            "  Downloading soc4onnx-1.0.2-py3-none-any.whl (5.7 kB)\n",
            "Collecting sne4onnx>=1.0.11\n",
            "  Downloading sne4onnx-1.0.11-py3-none-any.whl (7.0 kB)\n",
            "Collecting snc4onnx>=1.0.11\n",
            "  Downloading snc4onnx-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting sna4onnx>=1.0.6\n",
            "  Downloading sna4onnx-1.0.6-py3-none-any.whl (10 kB)\n",
            "Collecting svs4onnx>=1.0.0\n",
            "  Downloading svs4onnx-1.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting scs4onnx>=1.0.18\n",
            "  Downloading scs4onnx-1.0.18-py3-none-any.whl (10 kB)\n",
            "Collecting sam4onnx>=1.0.13\n",
            "  Downloading sam4onnx-1.0.13-py3-none-any.whl (10 kB)\n",
            "Collecting sbi4onnx>=1.0.4\n",
            "  Downloading sbi4onnx-1.0.4-py3-none-any.whl (6.6 kB)\n",
            "Collecting onnx2tf>=1.7.7\n",
            "  Downloading onnx2tf-1.7.21-py3-none-any.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.6/319.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting json2onnx>=2.0.2\n",
            "  Downloading json2onnx-2.0.2-py3-none-any.whl (4.8 kB)\n",
            "Collecting sde4onnx>=1.0.0\n",
            "  Downloading sde4onnx-1.0.0-py3-none-any.whl (5.5 kB)\n",
            "Installing collected packages: svs4onnx, ssi4onnx, ssc4onnx, sor4onnx, sog4onnx, sod4onnx, soc4onnx, soa4onnx, sng4onnx, sne4onnx, snd4onnx, snc4onnx, sit4onnx, sio4onnx, sed4onnx, sde4onnx, scs4onnx, scc4onnx, sbi4onnx, sam4onnx, onnx2tf, onnx2json, json2onnx, sna4onnx, simple_onnx_processing_tools\n",
            "Successfully installed json2onnx-2.0.2 onnx2json-2.0.4 onnx2tf-1.7.21 sam4onnx-1.0.13 sbi4onnx-1.0.4 scc4onnx-1.0.5 scs4onnx-1.0.18 sde4onnx-1.0.0 sed4onnx-1.0.5 simple_onnx_processing_tools-1.1.16 sio4onnx-1.0.2 sit4onnx-1.0.6 sna4onnx-1.0.6 snc4onnx-1.0.11 snd4onnx-1.1.6 sne4onnx-1.0.11 sng4onnx-1.0.1 soa4onnx-1.0.3 soc4onnx-1.0.2 sod4onnx-1.0.0 sog4onnx-1.0.15 sor4onnx-1.0.5 ssc4onnx-1.0.4 ssi4onnx-1.0.2 svs4onnx-1.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: onnx2tf in /usr/local/lib/python3.9/dist-packages (1.7.21)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/meituan/YOLOv6\n",
        "#https://github.com/meituan/YOLOv6.git\n",
        "%cd /content/YOLOv6\n",
        "!python3.9 -m pip install -r requirements.txt  # install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDLvqGGxAvM6",
        "outputId": "e0ff5706-7e07-4f7a-f6dc-95667b309cdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'YOLOv6'...\n",
            "remote: Enumerating objects: 2994, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 2994 (delta 122), reused 176 (delta 103), pack-reused 2777\u001b[K\n",
            "Receiving objects: 100% (2994/2994), 44.14 MiB | 16.51 MiB/s, done.\n",
            "Resolving deltas: 100% (1695/1695), done.\n",
            "/content/YOLOv6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (0.14.1+cu116)\n",
            "Collecting numpy>=1.24.0\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (1.10.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (4.65.0)\n",
            "Collecting addict>=2.4.0\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.10.1)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (2.0.6)\n",
            "Requirement already satisfied: onnx>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (1.13.1)\n",
            "Collecting onnx-simplifier>=0.3.6\n",
            "  Downloading onnx_simplifier-0.4.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.25.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (67.6.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.51.3)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.5.3)\n",
            "Collecting onnx>=1.10.0\n",
            "  Downloading onnx-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (13.3.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (6.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (4.39.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.1.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.2)\n",
            "Installing collected packages: addict, protobuf, numpy, thop, onnx, onnx-simplifier\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: onnx\n",
            "    Found existing installation: onnx 1.13.1\n",
            "    Uninstalling onnx-1.13.1:\n",
            "      Successfully uninstalled onnx-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\n",
            "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 numpy-1.24.2 onnx-1.12.0 onnx-simplifier-0.4.17 protobuf-3.19.6 thop-0.1.1.post2209072238\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sa_XPRKAZnm",
        "outputId": "49872384-3a92-4a7e-c5e4-c78c06f1f612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOv6\n",
            "Namespace(weights='yolov6m.pt', img_size=[480, 640], batch_size=1, half=False, inplace=False, simplify=True, dynamic_batch=False, end2end=False, trt_version=8, ort=False, with_preprocess=False, topk_all=100, iou_thres=0.45, conf_thres=0.4, device='0')\n",
            "Loading checkpoint from yolov6m.pt\n",
            "\n",
            "Fusing model...\n",
            "===================\n",
            "Model(\n",
            "  (backbone): CSPBepBackbone(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_reparam): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): BepC3(\n",
            "        (cv1): Conv_C3(\n",
            "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv_C3(\n",
            "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): Conv_C3(\n",
            "          (conv): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): RepBlock(\n",
            "          (conv1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): BepC3(\n",
            "        (cv1): Conv_C3(\n",
            "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv_C3(\n",
            "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): Conv_C3(\n",
            "          (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): RepBlock(\n",
            "          (conv1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "            (1): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): BepC3(\n",
            "        (cv1): Conv_C3(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv_C3(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): Conv_C3(\n",
            "          (conv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): RepBlock(\n",
            "          (conv1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "            (1): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "            (2): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "            (3): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): BepC3(\n",
            "        (cv1): Conv_C3(\n",
            "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv_C3(\n",
            "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): Conv_C3(\n",
            "          (conv): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): RepBlock(\n",
            "          (conv1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): BottleRep(\n",
            "              (conv1): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (conv2): RepVGGBlock(\n",
            "                (nonlinearity): ReLU(inplace=True)\n",
            "                (se): Identity()\n",
            "                (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): CSPRepPANNeck(\n",
            "    (Rep_p4): BepC3(\n",
            "      (cv1): Conv_C3(\n",
            "        (conv): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv_C3(\n",
            "        (conv): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv3): Conv_C3(\n",
            "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (m): RepBlock(\n",
            "        (conv1): BottleRep(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (conv2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): BepC3(\n",
            "      (cv1): Conv_C3(\n",
            "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv_C3(\n",
            "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv3): Conv_C3(\n",
            "        (conv): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (m): RepBlock(\n",
            "        (conv1): BottleRep(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (conv2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_n3): BepC3(\n",
            "      (cv1): Conv_C3(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv_C3(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv3): Conv_C3(\n",
            "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (m): RepBlock(\n",
            "        (conv1): BottleRep(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (conv2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): BepC3(\n",
            "      (cv1): Conv_C3(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv_C3(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv3): Conv_C3(\n",
            "        (conv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (m): RepBlock(\n",
            "        (conv1): BottleRep(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (conv2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): BottleRep(\n",
            "            (conv1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (conv2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer0): SimConv(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample0): Transpose(\n",
            "      (upsample_transpose): ConvTranspose2d(192, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (reduce_layer1): SimConv(\n",
            "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample1): Transpose(\n",
            "      (upsample_transpose): ConvTranspose2d(96, 96, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (downsample2): SimConv(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (downsample1): SimConv(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(384, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(96, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(192, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(384, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "===================\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/YOLOv6/deploy/ONNX/export_onnx.py\", line 97, in <module>\n",
            "    y = model(img)  # dry run\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/YOLOv6/yolov6/models/yolo.py\", line 34, in forward\n",
            "    x = self.backbone(x)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/YOLOv6/yolov6/models/efficientrep.py\", line 355, in forward\n",
            "    if self.fuse_P2:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1269, in __getattr__\n",
            "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
            "AttributeError: 'CSPBepBackbone' object has no attribute 'fuse_P2'\n"
          ]
        }
      ],
      "source": [
        "%cd /content/YOLOv6\n",
        "model = 'yolov6m' #@param [\"yolov6m\",\"yolov6s_base\", \"yolov6l_base\", \"yolov6m_base\"]\n",
        "input_width = 640 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
        "input_height = 480 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
        "end2end = False #@param {type:\"boolean\"}\n",
        "\n",
        "import os.path\n",
        "torch_model_name = f'{model}.pt'\n",
        "if not os.path.exists(torch_model_name):\n",
        "  !wget https://github.com/meituan/YOLOv6/releases/download/0.2.0/{torch_model_name}\n",
        "#https://github.com/meituan/YOLOv6/releases/download/0.2.0/yolov6m.pt\n",
        "if end2end:\n",
        "  !python3.9 deploy/ONNX/export_onnx.py --weights {torch_model_name} --img {input_height} {input_width} --batch 1 --simplify  --end2end --ort\n",
        "else:\n",
        "  !python3.9 deploy/ONNX/export_onnx.py --weights {torch_model_name} --img {input_height} {input_width} --batch 1 --simplify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "torch_model_name = f'{model}.pt'\n",
        "if not os.path.exists(torch_model_name):\n",
        "  !wget https://github.com/meituan/YOLOv6/releases/download/0.2.0/{torch_model_name}\n",
        "#https://github.com/meituan/YOLOv6/releases/download/0.2.0/yolov6m.pt\n",
        "if end2end:\n",
        "  !python3.9 deploy/ONNX/export_onnx.py --weights {torch_model_name} --img {input_height} {input_width} --batch 1 --simplify  --end2end --ort\n",
        "else:\n",
        "  !python3.9 deploy/ONNX/export_onnx.py --weights {torch_model_name} --img {input_height} {input_width} --batch 1 --simplify"
      ],
      "metadata": {
        "id": "Qb7k9afxKKIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d493f9-667b-47bb-c280-01d38e48e771"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights='yolov6m.pt', img_size=[480, 640], batch_size=1, half=False, inplace=False, simplify=True, dynamic_batch=False, end2end=False, trt_version=8, ort=False, with_preprocess=False, topk_all=100, iou_thres=0.45, conf_thres=0.4, device='0')\n",
            "Loading checkpoint from yolov6m.pt\n",
            "\n",
            "Fusing model...\n",
            "===================\n",
            "Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_reparam): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): SimConv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv4): SimConv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "        (cv5): SimConv(\n",
            "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv6): SimConv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv7): SimConv(\n",
            "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepBiFPANNeck(\n",
            "    (reduce_layer0): SimConv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (Bifusion0): BiFusion(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv2): SimConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv3): SimConv(\n",
            "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): SimConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer1): SimConv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (Bifusion1): BiFusion(\n",
            "      (cv1): SimConv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv2): SimConv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (cv3): SimConv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): SimConv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample2): SimConv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (Rep_n3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample1): SimConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (act): SiLU()\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "===================\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting to export ONNX...\n",
            "/content/YOLOv6/yolov6/assigners/anchor_generator.py:12: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  for i, stride in enumerate(fpn_strides):\n",
            "\n",
            "Starting to simplify ONNX...\n",
            "ONNX export success, saved as yolov6m.onnx\n",
            "\n",
            "Export complete (7.07s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/YOLOv6\n",
        "model = 'yolov6m' #@param [\"yolov6m\",\"yolov6s_base\", \"yolov6l_base\", \"yolov6m_base\"]\n",
        "input_width = 640 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
        "input_height = 640 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
        "end2end = False #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy9ZTGSgBbwG",
        "outputId": "aff25dbd-901b-4f18-ccc3-04b042efb0e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOv6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "torch_model_name = f'{model}.pt'"
      ],
      "metadata": {
        "id": "pN7I3fEqCVeW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVPyyyL2Cin-",
        "outputId": "8eee8b2e-479d-45a1-ba0f-6a83f1afd283"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolov6m.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.9 deploy/ONNX/export_onnx.py --weights {torch_model_name} --batch 1 --simplify  --end2end --ort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxjdkCF9BUUl",
        "outputId": "ab2e7961-3fa5-41f2-fed9-71d9868edf94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights='yolov6m.pt', img_size=[640, 640], batch_size=1, half=False, inplace=False, simplify=True, dynamic_batch=False, end2end=True, trt_version=8, ort=True, with_preprocess=False, topk_all=100, iou_thres=0.45, conf_thres=0.4, device='0')\n",
            "Loading checkpoint from yolov6m.pt\n",
            "\n",
            "Fusing model...\n",
            "===================\n",
            "End2End(\n",
            "  (model): Model(\n",
            "    (backbone): EfficientRep(\n",
            "      (stem): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_reparam): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (ERBlock_2): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepBlock(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ERBlock_3): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepBlock(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ERBlock_4): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepBlock(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (2): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (3): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (4): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ERBlock_5): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (1): RepBlock(\n",
            "          (conv1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (block): Sequential(\n",
            "            (0): RepVGGBlock(\n",
            "              (nonlinearity): ReLU(inplace=True)\n",
            "              (se): Identity()\n",
            "              (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): SimCSPSPPF(\n",
            "          (cv1): SimConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "          (cv2): SimConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "          (cv3): SimConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "          (cv4): SimConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "          (cv5): SimConv(\n",
            "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "          (cv6): SimConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "          (cv7): SimConv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (neck): RepBiFPANNeck(\n",
            "      (reduce_layer0): SimConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (Bifusion0): BiFusion(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): SimConv(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (upsample): Transpose(\n",
            "          (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "        )\n",
            "        (downsample): SimConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (Rep_p4): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (reduce_layer1): SimConv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (Bifusion1): BiFusion(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv3): SimConv(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (upsample): Transpose(\n",
            "          (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "        )\n",
            "        (downsample): SimConv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (Rep_p3): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample2): SimConv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (Rep_n3): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample1): SimConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (Rep_n4): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (detect): Detect(\n",
            "      (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (stems): ModuleList(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "        (2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (cls_convs): ModuleList(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "        (2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (reg_convs): ModuleList(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "        (2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (cls_preds): ModuleList(\n",
            "        (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): Conv2d(128, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (2): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (reg_preds): ModuleList(\n",
            "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (end2end): ONNX_ORT()\n",
            ")\n",
            "===================\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting to export ONNX...\n",
            "/content/YOLOv6/yolov6/assigners/anchor_generator.py:12: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  for i, stride in enumerate(fpn_strides):\n",
            "/content/YOLOv6/yolov6/models/end2end.py:27: FutureWarning: 'torch.onnx._patch_torch._graph_op' is deprecated in version 1.13 and will be removed in version 1.14. Please note 'g.op()' is to be removed from torch.Graph. Please open a GitHub issue if you need this functionality..\n",
            "  return g.op(\"NonMaxSuppression\", boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/onnx/symbolic_opset9.py:5408: UserWarning: Exporting aten::index operator of advanced indexing in opset 13 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n",
            "\u001b[1;35mInstalling onnxruntime by `/usr/bin/python3.9 -m pip install --user \u001b[0m\n",
            "\u001b[1;35monnxruntime`, please wait for a moment..\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (23.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.24.2)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (3.19.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime) (1.7.1)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "\u001b[33m  WARNING: The script humanfriendly is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mSimplifier failure: No module named 'onnxruntime'\n",
            "ONNX export success, saved as yolov6m.onnx\n",
            "\n",
            "Export complete (20.23s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/YOLOv6\n",
        "onnx_model_name = f'{model}.onnx'\n",
        "!onnx2tf -i {onnx_model_name}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq72NvHtBt1F",
        "outputId": "75bf2b99-13f6-4ce0-b971-06f40873d403"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOv6\n",
            "\n",
            "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃               ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add           │ 2              │ 2                │\n",
            "│ Concat        │ 10             │ 10               │\n",
            "│ Conv          │ 69             │ 69               │\n",
            "│ ConvTranspose │ 2              │ 2                │\n",
            "│ Div           │ 1              │ 1                │\n",
            "│ MaxPool       │ 3              │ 3                │\n",
            "│ Mul           │ 10             │ 10               │\n",
            "│ Relu          │ 54             │ 54               │\n",
            "│ Reshape       │ 6              │ 6                │\n",
            "│ Sigmoid       │ 12             │ 12               │\n",
            "│ Split         │ 1              │ 1                │\n",
            "│ Sub           │ 2              │ 2                │\n",
            "│ Transpose     │ 2              │ 2                │\n",
            "│ Model Size    │ 70.7MiB        │ 70.7MiB          │\n",
            "└───────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃               ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add           │ 2              │ 2                │\n",
            "│ Concat        │ 10             │ 10               │\n",
            "│ Conv          │ 69             │ 69               │\n",
            "│ ConvTranspose │ 2              │ 2                │\n",
            "│ Div           │ 1              │ 1                │\n",
            "│ MaxPool       │ 3              │ 3                │\n",
            "│ Mul           │ 10             │ 10               │\n",
            "│ Relu          │ 54             │ 54               │\n",
            "│ Reshape       │ 6              │ 6                │\n",
            "│ Sigmoid       │ 12             │ 12               │\n",
            "│ Split         │ 1              │ 1                │\n",
            "│ Sub           │ 2              │ 2                │\n",
            "│ Transpose     │ 2              │ 2                │\n",
            "│ Model Size    │ 70.7MiB        │ 70.7MiB          │\n",
            "└───────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃               ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add           │ 2              │ 2                │\n",
            "│ Concat        │ 10             │ 10               │\n",
            "│ Conv          │ 69             │ 69               │\n",
            "│ ConvTranspose │ 2              │ 2                │\n",
            "│ Div           │ 1              │ 1                │\n",
            "│ MaxPool       │ 3              │ 3                │\n",
            "│ Mul           │ 10             │ 10               │\n",
            "│ Relu          │ 54             │ 54               │\n",
            "│ Reshape       │ 6              │ 6                │\n",
            "│ Sigmoid       │ 12             │ 12               │\n",
            "│ Split         │ 1              │ 1                │\n",
            "│ Sub           │ 2              │ 2                │\n",
            "│ Transpose     │ 2              │ 2                │\n",
            "│ Model Size    │ 70.7MiB        │ 70.7MiB          │\n",
            "└───────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "\u001b[32mModel optimizing complete!\u001b[0m\n",
            "\n",
            "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
            "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
            "\n",
            "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
            "\n",
            "\u001b[07mModel convertion started\u001b[0m ============================================================\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: images \u001b[32mshape\u001b[0m: [1, 3, 480, 640] \u001b[32mdtype\u001b[0m: float32\n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/stem/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: images \u001b[36mshape\u001b[0m: [1, 3, 480, 640] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.stem.rbr_reparam.weight \u001b[36mshape\u001b[0m: [32, 3, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.stem.rbr_reparam.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stem/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 240, 320] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 482, 642, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 240, 320, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/stem/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stem/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 240, 320] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stem/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 240, 320] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 240, 320, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 240, 320, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_2/ERBlock_2.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stem/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 240, 320] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_2.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 32, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_2.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1/Pad:0 \u001b[34mshape\u001b[0m: (1, 242, 322, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_2/ERBlock_2.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_2.1.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_2.1.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_2.1.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_2.1.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_3.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_3.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2/Pad:0 \u001b[34mshape\u001b[0m: (1, 122, 162, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/cv2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_2/ERBlock_2.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion1.cv2.conv.weight \u001b[36mshape\u001b[0m: [64, 64, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion1.cv2.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/cv2/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 120, 160, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_3.1.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_3.1.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/downsample/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 120, 160] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion1.downsample.conv.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion1.downsample.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3/Pad:0 \u001b[34mshape\u001b[0m: (1, 122, 162, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/downsample/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_3.1.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_3.1.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_3.1.block.1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_3.1.block.1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_3.1.block.2.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_3.1.block.2.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_4/Pad:0 \u001b[34mshape\u001b[0m: (1, 62, 82, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/cv2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion0.cv2.conv.weight \u001b[36mshape\u001b[0m: [128, 128, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion0.cv2.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/cv1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_3/ERBlock_3.1/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion1.cv1.conv.weight \u001b[36mshape\u001b[0m: [64, 128, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion1.cv1.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/cv2/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/cv1/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.1.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.1.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/downsample/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion0.downsample.conv.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion0.downsample.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_5/Pad:0 \u001b[34mshape\u001b[0m: (1, 62, 82, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/downsample/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.1.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.1.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.1.block.1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.1.block.1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.2/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.1.block.2.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.1.block.2.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.2/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.3/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.1.block.3.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.1.block.3.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.3/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.3/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.3/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.3/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.3/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_4.1.block.4.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_4.1.block.4.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [512, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_6/Pad:0 \u001b[34mshape\u001b[0m: (1, 32, 42, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/cv1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_4/ERBlock_4.1/block/block.4/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion0.cv1.conv.weight \u001b[36mshape\u001b[0m: [128, 256, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion0.cv1.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/cv1/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.1.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [512, 512, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.1.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 512, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.1.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [512, 512, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.1.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 512, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv1.conv.weight \u001b[36mshape\u001b[0m: [256, 512, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv1.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.1/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv2.conv.weight \u001b[36mshape\u001b[0m: [256, 512, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv2.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv1/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv2/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv3/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv3.conv.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv3.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv3/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_27/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv4.conv.weight \u001b[36mshape\u001b[0m: [256, 256, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv4.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_27/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m/MaxPool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_1/MaxPool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_1/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_2/MaxPool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_1/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_2/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/Concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv4/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/m_2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_1/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_2/max_pool:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv5/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv5.conv.weight \u001b[36mshape\u001b[0m: [256, 1024, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv5.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv5/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv5/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv5/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv5/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_29/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv6/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv5/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv6.conv.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv6.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv6/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_29/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv6/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv6/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv6/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_30/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/Concat_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv6/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/Concat_1_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_30/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_1/concat:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv7/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/Concat_1_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.ERBlock_5.2.cv7.conv.weight \u001b[36mshape\u001b[0m: [512, 512, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.ERBlock_5.2.cv7.conv.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv7/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_1/concat:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv7/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv7/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv7/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_31/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/reduce_layer0/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/ERBlock_5/ERBlock_5.2/cv7/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 512, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.reduce_layer0.conv.weight \u001b[36mshape\u001b[0m: [128, 512, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.reduce_layer0.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/reduce_layer0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_31/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/reduce_layer0/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/reduce_layer0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/reduce_layer0/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvTranspose \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/upsample/upsample_transpose/ConvTranspose\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/reduce_layer0/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion0.upsample.upsample_transpose.weight \u001b[36mshape\u001b[0m: [128, 128, 2, 2] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion0.upsample.upsample_transpose.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/upsample/upsample_transpose/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: conv2d_transpose_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \u001b[34mshape\u001b[0m: (2, 2, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 30, 40, 128] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.8.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/Concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/upsample/upsample_transpose/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/Bifusion0/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /neck/Bifusion0/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_2/concat:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/cv3/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion0.cv3.conv.weight \u001b[36mshape\u001b[0m: [128, 384, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion0.cv3.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/cv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_2/concat:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion0/cv3/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/cv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion0/cv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_33/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion0/cv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p4.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p4.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_33/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_34/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p4.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p4.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_34/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_35/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/block/block.1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p4.block.1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p4.block.1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_35/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/block/block.1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_36/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/block/block.2/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p4.block.2.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p4.block.2.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_36/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p4/block/block.2/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p4/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_37/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/reduce_layer1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p4/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.reduce_layer1.conv.weight \u001b[36mshape\u001b[0m: [64, 128, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.reduce_layer1.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/reduce_layer1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_37/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/reduce_layer1/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/reduce_layer1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/reduce_layer1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvTranspose \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/upsample/upsample_transpose/ConvTranspose\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/reduce_layer1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion1.upsample.upsample_transpose.weight \u001b[36mshape\u001b[0m: [64, 64, 2, 2] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion1.upsample.upsample_transpose.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/upsample/upsample_transpose/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: conv2d_transpose_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \u001b[34mshape\u001b[0m: (2, 2, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 60, 80, 64] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.8.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/Concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/upsample/upsample_transpose/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/Bifusion1/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /neck/Bifusion1/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_3/concat:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/cv3/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Bifusion1.cv3.conv.weight \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Bifusion1.cv3.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/cv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_3/concat:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Bifusion1/cv3/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/cv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Bifusion1/cv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_39/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Bifusion1/cv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p3.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p3.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_39/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_40/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p3.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p3.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_40/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_43/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_43/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_41/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/block/block.1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p3.block.1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p3.block.1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_41/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/block/block.1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_42/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/block/block.2/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_p3.block.2.rbr_reparam.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_p3.block.2.rbr_reparam.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_42/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_p3/block/block.2/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_p3/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_43/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/downsample2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.downsample2.conv.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.downsample2.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/downsample2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_7/Pad:0 \u001b[34mshape\u001b[0m: (1, 62, 82, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/stems.0/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_p3/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.stems.0.conv.weight \u001b[36mshape\u001b[0m: [64, 64, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.stems.0.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_43/Relu:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/downsample2/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/downsample2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/downsample2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_44/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/stems.0/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.0/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /neck/Concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/downsample2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/reduce_layer1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_44/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_4/concat:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/stems.0/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/stems.0/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n3.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n3.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_4/concat:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.0/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.cls_convs.0.conv.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.cls_convs.0.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.0/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.reg_convs.0.conv.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.reg_convs.0.conv.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_45/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.0/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.0/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_1/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.0/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.0/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_2/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n3.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n3.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_45/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.0/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/cls_convs.0/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_1/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_3/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.0/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.0/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/reg_convs.0/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_2/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_46/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/cls_preds.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.cls_preds.0.weight \u001b[36mshape\u001b[0m: [9, 64, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.cls_preds.0.bias \u001b[36mshape\u001b[0m: [9] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_preds.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 9, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_3/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (9,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/reg_preds.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.0/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.reg_preds.0.weight \u001b[36mshape\u001b[0m: [4, 64, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.reg_preds.0.bias \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_preds.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 4, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (4,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/block/block.1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n3.block.1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n3.block.1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_46/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_preds.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 9, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 9, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_3/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 60, 80, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape \u001b[35monnx_op_name\u001b[0m: /detect/Reshape_4\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_preds.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 4, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_19_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Reshape_4_output_0 \u001b[36mshape\u001b[0m: [1, 4, 4800] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 60, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 4, 4800] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 4800) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/block/block.1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape \u001b[35monnx_op_name\u001b[0m: /detect/Reshape_3\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 9, 60, 80] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_18_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Reshape_3_output_0 \u001b[36mshape\u001b[0m: [1, 9, 4800] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1/transpose:0 \u001b[34mshape\u001b[0m: (1, 9, 60, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 9, 4800] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_1/Reshape:0 \u001b[34mshape\u001b[0m: (1, 9, 4800) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/block/block.2/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n3.block.2.rbr_reparam.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n3.block.2.rbr_reparam.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n3/block/block.2/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n3/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/downsample1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.downsample1.conv.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.downsample1.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/downsample1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_8/Pad:0 \u001b[34mshape\u001b[0m: (1, 32, 42, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/stems.1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n3/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.stems.1.conv.weight \u001b[36mshape\u001b[0m: [128, 128, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.stems.1.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/downsample1/act/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/downsample1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/downsample1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/stems.1/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.1/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_4/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /neck/Concat_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/downsample1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/reduce_layer0/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Concat_1_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_5/concat:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/stems.1/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/stems.1/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_4/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_7/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/conv1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Concat_1_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n4.conv1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n4.conv1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_5/concat:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.cls_convs.1.conv.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.cls_convs.1.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_7/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.1/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.reg_convs.1.conv.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.reg_convs.1.conv.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_7/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/conv1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/conv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.1/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.1/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_5/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.1/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.1/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_6/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/block/block.0/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/conv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n4.block.0.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n4.block.0.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.1/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/cls_convs.1/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_5/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_9/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.1/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/reg_convs.1/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_6/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_11/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/block/block.0/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/block/block.0/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/cls_preds.1/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.cls_preds.1.weight \u001b[36mshape\u001b[0m: [9, 128, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.cls_preds.1.bias \u001b[36mshape\u001b[0m: [9] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_preds.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 9, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_9/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (9,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/reg_preds.1/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.1/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.reg_preds.1.weight \u001b[36mshape\u001b[0m: [4, 128, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.reg_preds.1.bias \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_preds.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 4, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_11/Mul:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (4,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/block/block.1/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/block/block.0/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n4.block.1.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n4.block.1.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/Sigmoid_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_preds.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 9, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Sigmoid_1_output_0 \u001b[36mshape\u001b[0m: [1, 9, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_7/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 30, 40, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape \u001b[35monnx_op_name\u001b[0m: /detect/Reshape_6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_preds.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 4, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_21_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Reshape_6_output_0 \u001b[36mshape\u001b[0m: [1, 4, 1200] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_2/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 30, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 4, 1200] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 1200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/block/block.1/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/block/block.1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_52/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape \u001b[35monnx_op_name\u001b[0m: /detect/Reshape_5\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Sigmoid_1_output_0 \u001b[36mshape\u001b[0m: [1, 9, 30, 40] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_20_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Reshape_5_output_0 \u001b[36mshape\u001b[0m: [1, 9, 1200] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_3/transpose:0 \u001b[34mshape\u001b[0m: (1, 9, 30, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 9, 1200] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_3/Reshape:0 \u001b[34mshape\u001b[0m: (1, 9, 1200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/block/block.2/rbr_reparam/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/block/block.1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.Rep_n4.block.2.rbr_reparam.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.Rep_n4.block.2.rbr_reparam.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_52/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu \u001b[35monnx_op_name\u001b[0m: /neck/Rep_n4/block/block.2/nonlinearity/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/block/block.2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/Rep_n4/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_53/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/stems.2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/Rep_n4/block/block.2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.stems.2.conv.weight \u001b[36mshape\u001b[0m: [256, 256, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.stems.2.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_53/Relu:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/stems.2/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.2/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_8/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/stems.2/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/stems.2/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/stems.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_8/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_13/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.cls_convs.2.conv.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.cls_convs.2.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_13/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.2/conv/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/stems.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.reg_convs.2.conv.weight \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.reg_convs.2.conv.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_13/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_68/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.2/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.2/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_9/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.2/act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.2/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_68/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_10/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/cls_convs.2/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/cls_convs.2/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_convs.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_9/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_15/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/reg_convs.2/act/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/reg_convs.2/act/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_convs.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_68/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_10/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_17/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/cls_preds.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_convs.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.cls_preds.2.weight \u001b[36mshape\u001b[0m: [9, 256, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.cls_preds.2.bias \u001b[36mshape\u001b[0m: [9] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/cls_preds.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 9, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_15/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (9,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv \u001b[35monnx_op_name\u001b[0m: /detect/reg_preds.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_convs.2/act/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: detect.reg_preds.2.weight \u001b[36mshape\u001b[0m: [4, 256, 1, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: detect.reg_preds.2.bias \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/reg_preds.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 4, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_17/Mul:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (4,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid \u001b[35monnx_op_name\u001b[0m: /detect/Sigmoid_2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/cls_preds.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 9, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Sigmoid_2_output_0 \u001b[36mshape\u001b[0m: [1, 9, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_11/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 15, 20, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape \u001b[35monnx_op_name\u001b[0m: /detect/Reshape_8\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/reg_preds.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 4, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_23_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Reshape_8_output_0 \u001b[36mshape\u001b[0m: [1, 4, 300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_4/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 15, 20) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 4, 300] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_4/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape \u001b[35monnx_op_name\u001b[0m: /detect/Reshape_7\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Sigmoid_2_output_0 \u001b[36mshape\u001b[0m: [1, 9, 15, 20] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_22_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Reshape_7_output_0 \u001b[36mshape\u001b[0m: [1, 9, 300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_5/transpose:0 \u001b[34mshape\u001b[0m: (1, 9, 15, 20) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 9, 300] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_5/Reshape:0 \u001b[34mshape\u001b[0m: (1, 9, 300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /detect/Concat_5\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Reshape_4_output_0 \u001b[36mshape\u001b[0m: [1, 4, 4800] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Reshape_6_output_0 \u001b[36mshape\u001b[0m: [1, 4, 1200] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /detect/Reshape_8_output_0 \u001b[36mshape\u001b[0m: [1, 4, 300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Concat_5_output_0 \u001b[36mshape\u001b[0m: [1, 4, 6300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 4800) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 1200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_4/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_6/concat:0 \u001b[34mshape\u001b[0m: (1, 4, 6300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /detect/Concat_4\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Reshape_3_output_0 \u001b[36mshape\u001b[0m: [1, 9, 4800] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Reshape_5_output_0 \u001b[36mshape\u001b[0m: [1, 9, 1200] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /detect/Reshape_7_output_0 \u001b[36mshape\u001b[0m: [1, 9, 300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Concat_4_output_0 \u001b[36mshape\u001b[0m: [1, 9, 6300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_1/Reshape:0 \u001b[34mshape\u001b[0m: (1, 9, 4800) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_3/Reshape:0 \u001b[34mshape\u001b[0m: (1, 9, 1200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_5/Reshape:0 \u001b[34mshape\u001b[0m: (1, 9, 300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_7/concat:0 \u001b[34mshape\u001b[0m: (1, 9, 6300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose \u001b[35monnx_op_name\u001b[0m: /detect/Transpose_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Concat_5_output_0 \u001b[36mshape\u001b[0m: [1, 4, 6300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Transpose_1_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 4] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_6/concat:0 \u001b[34mshape\u001b[0m: (1, 4, 6300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 2, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_6/transpose:0 \u001b[34mshape\u001b[0m: (1, 6300, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose \u001b[35monnx_op_name\u001b[0m: /detect/Transpose\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Concat_4_output_0 \u001b[36mshape\u001b[0m: [1, 9, 6300] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Transpose_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 9] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_7/concat:0 \u001b[34mshape\u001b[0m: (1, 9, 6300) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 2, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_7/transpose:0 \u001b[34mshape\u001b[0m: (1, 6300, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Split \u001b[35monnx_op_name\u001b[0m: /detect/Split\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Transpose_1_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 4] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_24_output_0 \u001b[36mshape\u001b[0m: [2] \u001b[36mdtype\u001b[0m: <class 'numpy.int64'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Split_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.2\u001b[0m: /detect/Split_output_1 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: split\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.value\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_6/transpose:0 \u001b[34mshape\u001b[0m: (1, 6300, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.num_or_size_splits\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: int64 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.num\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:1 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sub \u001b[35monnx_op_name\u001b[0m: /detect/Sub\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Concat_3_output_0 \u001b[36mshape\u001b[0m: [6300, 2] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Split_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: subtract\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add \u001b[35monnx_op_name\u001b[0m: /detect/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Concat_3_output_0 \u001b[36mshape\u001b[0m: (6300, 2) \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Split_output_1 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Add_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:1 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add \u001b[35monnx_op_name\u001b[0m: /detect/Add_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Add_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Add_1_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sub \u001b[35monnx_op_name\u001b[0m: /detect/Sub_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Add_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Sub_1_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: subtract\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_1/Sub:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Div \u001b[35monnx_op_name\u001b[0m: /detect/Div\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Add_1_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_25_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Div_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: divide\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide/truediv:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /detect/Concat_6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Div_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Sub_1_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 2] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Concat_6_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 4] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide/truediv:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_1/Sub:0 \u001b[34mshape\u001b[0m: (1, 6300, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_8/concat:0 \u001b[34mshape\u001b[0m: (1, 6300, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul \u001b[35monnx_op_name\u001b[0m: /detect/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Concat_6_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 4] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_26_output_0 \u001b[36mshape\u001b[0m: [6300, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /detect/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 4] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_8/concat:0 \u001b[34mshape\u001b[0m: (1, 6300, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 6300, 1) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_20/Mul:0 \u001b[34mshape\u001b[0m: (1, 6300, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat \u001b[35monnx_op_name\u001b[0m: /detect/Concat_7\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /detect/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 4] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /detect/Constant_27_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 1] \u001b[36mdtype\u001b[0m: <class 'numpy.float32'>\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /detect/Transpose_output_0 \u001b[36mshape\u001b[0m: [1, 6300, 9] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: outputs \u001b[36mshape\u001b[0m: [1, 6300, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_20/Mul:0 \u001b[34mshape\u001b[0m: (1, 6300, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mshape\u001b[0m: (1, 6300, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_7/transpose:0 \u001b[34mshape\u001b[0m: (1, 6300, 9) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_9/concat:0 \u001b[34mshape\u001b[0m: (1, 6300, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "Model: \"model\"\n",
            "____________________________________________________________________________________________________________________________________________\n",
            " Layer (type)                                 Output Shape                   Param #         Connected to                                   \n",
            "============================================================================================================================================\n",
            " images (InputLayer)                          [(1, 480, 640, 3)]             0               []                                             \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad (TFOpLambda)                (1, 482, 642, 3)               0               ['images[0][0]']                               \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution (TFOpLambda)               (1, 240, 320, 32)              0               ['tf.compat.v1.pad[0][0]']                     \n",
            "                                                                                                                                            \n",
            " tf.math.add (TFOpLambda)                     (1, 240, 320, 32)              0               ['tf.nn.convolution[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.nn.relu (TFOpLambda)                      (1, 240, 320, 32)              0               ['tf.math.add[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_1 (TFOpLambda)              (1, 242, 322, 32)              0               ['tf.nn.relu[0][0]']                           \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_1 (TFOpLambda)             (1, 120, 160, 64)              0               ['tf.compat.v1.pad_1[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.add_1 (TFOpLambda)                   (1, 120, 160, 64)              0               ['tf.nn.convolution_1[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_1 (TFOpLambda)                    (1, 120, 160, 64)              0               ['tf.math.add_1[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_2 (TFOpLambda)             (1, 120, 160, 64)              0               ['tf.nn.relu_1[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.add_2 (TFOpLambda)                   (1, 120, 160, 64)              0               ['tf.nn.convolution_2[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_2 (TFOpLambda)                    (1, 120, 160, 64)              0               ['tf.math.add_2[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_3 (TFOpLambda)             (1, 120, 160, 64)              0               ['tf.nn.relu_2[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.add_3 (TFOpLambda)                   (1, 120, 160, 64)              0               ['tf.nn.convolution_3[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_3 (TFOpLambda)                    (1, 120, 160, 64)              0               ['tf.math.add_3[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_2 (TFOpLambda)              (1, 122, 162, 64)              0               ['tf.nn.relu_3[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_4 (TFOpLambda)             (1, 60, 80, 128)               0               ['tf.compat.v1.pad_2[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.add_4 (TFOpLambda)                   (1, 60, 80, 128)               0               ['tf.nn.convolution_4[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_4 (TFOpLambda)                    (1, 60, 80, 128)               0               ['tf.math.add_4[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_6 (TFOpLambda)             (1, 60, 80, 128)               0               ['tf.nn.relu_4[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.add_6 (TFOpLambda)                   (1, 60, 80, 128)               0               ['tf.nn.convolution_6[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_6 (TFOpLambda)                    (1, 60, 80, 128)               0               ['tf.math.add_6[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_8 (TFOpLambda)             (1, 60, 80, 128)               0               ['tf.nn.relu_6[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.add_8 (TFOpLambda)                   (1, 60, 80, 128)               0               ['tf.nn.convolution_8[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_8 (TFOpLambda)                    (1, 60, 80, 128)               0               ['tf.math.add_8[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_9 (TFOpLambda)             (1, 60, 80, 128)               0               ['tf.nn.relu_8[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.add_9 (TFOpLambda)                   (1, 60, 80, 128)               0               ['tf.nn.convolution_9[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_9 (TFOpLambda)                    (1, 60, 80, 128)               0               ['tf.math.add_9[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_10 (TFOpLambda)            (1, 60, 80, 128)               0               ['tf.nn.relu_9[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.add_10 (TFOpLambda)                  (1, 60, 80, 128)               0               ['tf.nn.convolution_10[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_10 (TFOpLambda)                   (1, 60, 80, 128)               0               ['tf.math.add_10[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_4 (TFOpLambda)              (1, 62, 82, 128)               0               ['tf.nn.relu_10[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_11 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.compat.v1.pad_4[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.add_11 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_11[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_11 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_11[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_14 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.nn.relu_11[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_14 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_14[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_14 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_14[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_16 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.nn.relu_14[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_16 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_16[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_16 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_16[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_17 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.nn.relu_16[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_17 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_17[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_17 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_17[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_18 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.nn.relu_17[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_18 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_18[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_18 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_18[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_19 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.nn.relu_18[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_19 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_19[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_19 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_19[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_20 (TFOpLambda)            (1, 30, 40, 256)               0               ['tf.nn.relu_19[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_20 (TFOpLambda)                  (1, 30, 40, 256)               0               ['tf.nn.convolution_20[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_20 (TFOpLambda)                   (1, 30, 40, 256)               0               ['tf.math.add_20[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_6 (TFOpLambda)              (1, 32, 42, 256)               0               ['tf.nn.relu_20[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_21 (TFOpLambda)            (1, 15, 20, 512)               0               ['tf.compat.v1.pad_6[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.add_21 (TFOpLambda)                  (1, 15, 20, 512)               0               ['tf.nn.convolution_21[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_21 (TFOpLambda)                   (1, 15, 20, 512)               0               ['tf.math.add_21[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_23 (TFOpLambda)            (1, 15, 20, 512)               0               ['tf.nn.relu_21[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_23 (TFOpLambda)                  (1, 15, 20, 512)               0               ['tf.nn.convolution_23[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_23 (TFOpLambda)                   (1, 15, 20, 512)               0               ['tf.math.add_23[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_24 (TFOpLambda)            (1, 15, 20, 512)               0               ['tf.nn.relu_23[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_24 (TFOpLambda)                  (1, 15, 20, 512)               0               ['tf.nn.convolution_24[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_24 (TFOpLambda)                   (1, 15, 20, 512)               0               ['tf.math.add_24[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_25 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_24[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_25 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_25[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_25 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_25[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_27 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_25[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_27 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_27[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_27 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_27[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_28 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_27[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_28 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_28[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_28 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_28[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.nn.pool (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_28[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.nn.pool_1 (TFOpLambda)          (1, 15, 20, 256)               0               ['tf.compat.v1.nn.pool[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.nn.pool_2 (TFOpLambda)          (1, 15, 20, 256)               0               ['tf.compat.v1.nn.pool_1[0][0]']               \n",
            "                                                                                                                                            \n",
            " tf.concat (TFOpLambda)                       (1, 15, 20, 1024)              0               ['tf.nn.relu_28[0][0]',                        \n",
            "                                                                                              'tf.compat.v1.nn.pool[0][0]',                 \n",
            "                                                                                              'tf.compat.v1.nn.pool_1[0][0]',               \n",
            "                                                                                              'tf.compat.v1.nn.pool_2[0][0]']               \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_29 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.concat[0][0]']                            \n",
            "                                                                                                                                            \n",
            " tf.math.add_29 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_29[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_29 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_29[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_26 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_24[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_30 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_29[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_26 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_26[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_30 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_30[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_26 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_26[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_30 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_30[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.concat_1 (TFOpLambda)                     (1, 15, 20, 512)               0               ['tf.nn.relu_26[0][0]',                        \n",
            "                                                                                              'tf.nn.relu_30[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_31 (TFOpLambda)            (1, 15, 20, 512)               0               ['tf.concat_1[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.math.add_31 (TFOpLambda)                  (1, 15, 20, 512)               0               ['tf.nn.convolution_31[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_12 (TFOpLambda)            (1, 60, 80, 128)               0               ['tf.nn.relu_10[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_31 (TFOpLambda)                   (1, 15, 20, 512)               0               ['tf.math.add_31[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.add_12 (TFOpLambda)                  (1, 60, 80, 128)               0               ['tf.nn.convolution_12[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_32 (TFOpLambda)            (1, 15, 20, 128)               0               ['tf.nn.relu_31[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_12 (TFOpLambda)                   (1, 60, 80, 128)               0               ['tf.math.add_12[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.add_32 (TFOpLambda)                  (1, 15, 20, 128)               0               ['tf.nn.convolution_32[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_5 (TFOpLambda)              (1, 62, 82, 128)               0               ['tf.nn.relu_12[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_32 (TFOpLambda)                   (1, 15, 20, 128)               0               ['tf.math.add_32[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_22 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_20[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_15 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.compat.v1.pad_5[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.conv2d_transpose (TFOpLambda)          (1, 30, 40, 128)               0               ['tf.nn.relu_32[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_22 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_22[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_15 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_15[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_33 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.conv2d_transpose[0][0]']               \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_22 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_22[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_15 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_15[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.concat_2 (TFOpLambda)                     (1, 30, 40, 384)               0               ['tf.math.add_33[0][0]',                       \n",
            "                                                                                              'tf.nn.relu_22[0][0]',                        \n",
            "                                                                                              'tf.nn.relu_15[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_33 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.concat_2[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.math.add_34 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_33[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_33 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_34[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_34 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_33[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_35 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_34[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_34 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_35[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_35 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_34[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_36 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_35[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_35 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_36[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_36 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_35[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_37 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_36[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_36 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_37[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_37 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_36[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_38 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_37[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_5 (TFOpLambda)             (1, 120, 160, 64)              0               ['tf.nn.relu_3[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_37 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_38[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.add_5 (TFOpLambda)                   (1, 120, 160, 64)              0               ['tf.nn.convolution_5[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_38 (TFOpLambda)            (1, 30, 40, 64)                0               ['tf.nn.relu_37[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_5 (TFOpLambda)                    (1, 120, 160, 64)              0               ['tf.math.add_5[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_39 (TFOpLambda)                  (1, 30, 40, 64)                0               ['tf.nn.convolution_38[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_3 (TFOpLambda)              (1, 122, 162, 64)              0               ['tf.nn.relu_5[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_38 (TFOpLambda)                   (1, 30, 40, 64)                0               ['tf.math.add_39[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_13 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.nn.relu_10[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_7 (TFOpLambda)             (1, 60, 80, 64)                0               ['tf.compat.v1.pad_3[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.conv2d_transpose_1 (TFOpLambda)        (1, 60, 80, 64)                0               ['tf.nn.relu_38[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_13 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_13[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_7 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.nn.convolution_7[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.math.add_40 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.conv2d_transpose_1[0][0]']             \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_13 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.math.add_13[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_7 (TFOpLambda)                    (1, 60, 80, 64)                0               ['tf.math.add_7[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.concat_3 (TFOpLambda)                     (1, 60, 80, 192)               0               ['tf.math.add_40[0][0]',                       \n",
            "                                                                                              'tf.nn.relu_13[0][0]',                        \n",
            "                                                                                              'tf.nn.relu_7[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_39 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.concat_3[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.math.add_41 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_39[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_39 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.math.add_41[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_40 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.nn.relu_39[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_42 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_40[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_40 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.math.add_42[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_41 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.nn.relu_40[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_43 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_41[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_41 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.math.add_43[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_42 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.nn.relu_41[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_44 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_42[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_42 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.math.add_44[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_43 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.nn.relu_42[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_45 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_43[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_43 (TFOpLambda)                   (1, 60, 80, 64)                0               ['tf.math.add_45[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_7 (TFOpLambda)              (1, 62, 82, 64)                0               ['tf.nn.relu_43[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_44 (TFOpLambda)            (1, 30, 40, 64)                0               ['tf.compat.v1.pad_7[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.add_46 (TFOpLambda)                  (1, 30, 40, 64)                0               ['tf.nn.convolution_44[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_44 (TFOpLambda)                   (1, 30, 40, 64)                0               ['tf.math.add_46[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.concat_4 (TFOpLambda)                     (1, 30, 40, 128)               0               ['tf.nn.relu_44[0][0]',                        \n",
            "                                                                                              'tf.nn.relu_38[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_46 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.concat_4[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.math.add_48 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_46[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_45 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_48[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_49 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_45[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_51 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_49[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_46 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_51[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_52 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_46[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_54 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_52[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_47 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_54[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_53 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_47[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_55 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_53[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_48 (TFOpLambda)                   (1, 30, 40, 128)               0               ['tf.math.add_55[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.pad_8 (TFOpLambda)              (1, 32, 42, 128)               0               ['tf.nn.relu_48[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_54 (TFOpLambda)            (1, 15, 20, 128)               0               ['tf.compat.v1.pad_8[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.add_56 (TFOpLambda)                  (1, 15, 20, 128)               0               ['tf.nn.convolution_54[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_49 (TFOpLambda)                   (1, 15, 20, 128)               0               ['tf.math.add_56[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.concat_5 (TFOpLambda)                     (1, 15, 20, 256)               0               ['tf.nn.relu_49[0][0]',                        \n",
            "                                                                                              'tf.nn.relu_32[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_56 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.concat_5[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.math.add_58 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_56[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_50 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_58[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_59 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_50[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_61 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_59[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_51 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_61[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_62 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_51[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_64 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_62[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_52 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_64[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_63 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_52[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_65 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_63[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.relu_53 (TFOpLambda)                   (1, 15, 20, 256)               0               ['tf.math.add_65[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_45 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.nn.relu_43[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_55 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.nn.relu_48[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_64 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.nn.relu_53[0][0]']                        \n",
            "                                                                                                                                            \n",
            " tf.math.add_47 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_45[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_57 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_55[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_66 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_64[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid (TFOpLambda)                 (1, 60, 80, 64)                0               ['tf.math.add_47[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_4 (TFOpLambda)               (1, 30, 40, 128)               0               ['tf.math.add_57[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_8 (TFOpLambda)               (1, 15, 20, 256)               0               ['tf.math.add_66[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_1 (TFOpLambda)              (1, 60, 80, 64)                0               ['tf.math.add_47[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid[0][0]']                      \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_7 (TFOpLambda)              (1, 30, 40, 128)               0               ['tf.math.add_57[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_4[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_13 (TFOpLambda)             (1, 15, 20, 256)               0               ['tf.math.add_66[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_8[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_48 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.math.multiply_1[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_58 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.math.multiply_7[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_66 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.math.multiply_13[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.math.add_50 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_48[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_60 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_58[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_68 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_66[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_2 (TFOpLambda)               (1, 60, 80, 64)                0               ['tf.math.add_50[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_6 (TFOpLambda)               (1, 30, 40, 128)               0               ['tf.math.add_60[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_10 (TFOpLambda)              (1, 15, 20, 256)               0               ['tf.math.add_68[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_5 (TFOpLambda)              (1, 60, 80, 64)                0               ['tf.math.add_50[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_2[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_11 (TFOpLambda)             (1, 30, 40, 128)               0               ['tf.math.add_60[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_6[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_17 (TFOpLambda)             (1, 15, 20, 256)               0               ['tf.math.add_68[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_10[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_51 (TFOpLambda)            (1, 60, 80, 4)                 0               ['tf.math.multiply_5[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_61 (TFOpLambda)            (1, 30, 40, 4)                 0               ['tf.math.multiply_11[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_68 (TFOpLambda)            (1, 15, 20, 4)                 0               ['tf.math.multiply_17[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.math.add_53 (TFOpLambda)                  (1, 60, 80, 4)                 0               ['tf.nn.convolution_51[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_63 (TFOpLambda)                  (1, 30, 40, 4)                 0               ['tf.nn.convolution_61[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_70 (TFOpLambda)                  (1, 15, 20, 4)                 0               ['tf.nn.convolution_68[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_47 (TFOpLambda)            (1, 60, 80, 64)                0               ['tf.math.multiply_1[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_57 (TFOpLambda)            (1, 30, 40, 128)               0               ['tf.math.multiply_7[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_65 (TFOpLambda)            (1, 15, 20, 256)               0               ['tf.math.multiply_13[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose (TFOpLambda)          (1, 4, 60, 80)                 0               ['tf.math.add_53[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_2 (TFOpLambda)        (1, 4, 30, 40)                 0               ['tf.math.add_63[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_4 (TFOpLambda)        (1, 4, 15, 20)                 0               ['tf.math.add_70[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.add_49 (TFOpLambda)                  (1, 60, 80, 64)                0               ['tf.nn.convolution_47[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_59 (TFOpLambda)                  (1, 30, 40, 128)               0               ['tf.nn.convolution_57[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_67 (TFOpLambda)                  (1, 15, 20, 256)               0               ['tf.nn.convolution_65[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.reshape (TFOpLambda)                      (1, 4, 4800)                   0               ['tf.compat.v1.transpose[0][0]']               \n",
            "                                                                                                                                            \n",
            " tf.reshape_2 (TFOpLambda)                    (1, 4, 1200)                   0               ['tf.compat.v1.transpose_2[0][0]']             \n",
            "                                                                                                                                            \n",
            " tf.reshape_4 (TFOpLambda)                    (1, 4, 300)                    0               ['tf.compat.v1.transpose_4[0][0]']             \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_1 (TFOpLambda)               (1, 60, 80, 64)                0               ['tf.math.add_49[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_5 (TFOpLambda)               (1, 30, 40, 128)               0               ['tf.math.add_59[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_9 (TFOpLambda)               (1, 15, 20, 256)               0               ['tf.math.add_67[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.concat_6 (TFOpLambda)                     (1, 4, 6300)                   0               ['tf.reshape[0][0]',                           \n",
            "                                                                                              'tf.reshape_2[0][0]',                         \n",
            "                                                                                              'tf.reshape_4[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_3 (TFOpLambda)              (1, 60, 80, 64)                0               ['tf.math.add_49[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_1[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_9 (TFOpLambda)              (1, 30, 40, 128)               0               ['tf.math.add_59[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_5[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_15 (TFOpLambda)             (1, 15, 20, 256)               0               ['tf.math.add_67[0][0]',                       \n",
            "                                                                                              'tf.math.sigmoid_9[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_6 (TFOpLambda)        (1, 6300, 4)                   0               ['tf.concat_6[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_50 (TFOpLambda)            (1, 60, 80, 9)                 0               ['tf.math.multiply_3[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_60 (TFOpLambda)            (1, 30, 40, 9)                 0               ['tf.math.multiply_9[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.nn.convolution_67 (TFOpLambda)            (1, 15, 20, 9)                 0               ['tf.math.multiply_15[0][0]']                  \n",
            "                                                                                                                                            \n",
            " tf.split (TFOpLambda)                        [(1, 6300, 2),                 0               ['tf.compat.v1.transpose_6[0][0]']             \n",
            "                                               (1, 6300, 2)]                                                                                \n",
            "                                                                                                                                            \n",
            " tf.math.add_52 (TFOpLambda)                  (1, 60, 80, 9)                 0               ['tf.nn.convolution_50[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_62 (TFOpLambda)                  (1, 30, 40, 9)                 0               ['tf.nn.convolution_60[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.add_69 (TFOpLambda)                  (1, 15, 20, 9)                 0               ['tf.nn.convolution_67[0][0]']                 \n",
            "                                                                                                                                            \n",
            " tf.math.subtract (TFOpLambda)                (1, 6300, 2)                   0               ['tf.split[0][0]']                             \n",
            "                                                                                                                                            \n",
            " tf.math.add_71 (TFOpLambda)                  (1, 6300, 2)                   0               ['tf.split[0][1]']                             \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_3 (TFOpLambda)               (1, 60, 80, 9)                 0               ['tf.math.add_52[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_7 (TFOpLambda)               (1, 30, 40, 9)                 0               ['tf.math.add_62[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.sigmoid_11 (TFOpLambda)              (1, 15, 20, 9)                 0               ['tf.math.add_69[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.add_72 (TFOpLambda)                  (1, 6300, 2)                   0               ['tf.math.subtract[0][0]',                     \n",
            "                                                                                              'tf.math.add_71[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_1 (TFOpLambda)        (1, 9, 60, 80)                 0               ['tf.math.sigmoid_3[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_3 (TFOpLambda)        (1, 9, 30, 40)                 0               ['tf.math.sigmoid_7[0][0]']                    \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_5 (TFOpLambda)        (1, 9, 15, 20)                 0               ['tf.math.sigmoid_11[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.math.divide (TFOpLambda)                  (1, 6300, 2)                   0               ['tf.math.add_72[0][0]']                       \n",
            "                                                                                                                                            \n",
            " tf.math.subtract_1 (TFOpLambda)              (1, 6300, 2)                   0               ['tf.math.add_71[0][0]',                       \n",
            "                                                                                              'tf.math.subtract[0][0]']                     \n",
            "                                                                                                                                            \n",
            " tf.reshape_1 (TFOpLambda)                    (1, 9, 4800)                   0               ['tf.compat.v1.transpose_1[0][0]']             \n",
            "                                                                                                                                            \n",
            " tf.reshape_3 (TFOpLambda)                    (1, 9, 1200)                   0               ['tf.compat.v1.transpose_3[0][0]']             \n",
            "                                                                                                                                            \n",
            " tf.reshape_5 (TFOpLambda)                    (1, 9, 300)                    0               ['tf.compat.v1.transpose_5[0][0]']             \n",
            "                                                                                                                                            \n",
            " tf.concat_8 (TFOpLambda)                     (1, 6300, 4)                   0               ['tf.math.divide[0][0]',                       \n",
            "                                                                                              'tf.math.subtract_1[0][0]']                   \n",
            "                                                                                                                                            \n",
            " tf.concat_7 (TFOpLambda)                     (1, 9, 6300)                   0               ['tf.reshape_1[0][0]',                         \n",
            "                                                                                              'tf.reshape_3[0][0]',                         \n",
            "                                                                                              'tf.reshape_5[0][0]']                         \n",
            "                                                                                                                                            \n",
            " tf.math.multiply_20 (TFOpLambda)             (1, 6300, 4)                   0               ['tf.concat_8[0][0]']                          \n",
            "                                                                                                                                            \n",
            " tf.compat.v1.transpose_7 (TFOpLambda)        (1, 6300, 9)                   0               ['tf.concat_7[0][0]']                          \n",
            "                                                                                                                                            \n",
            " outputs (TFOpLambda)                         (1, 6300, 14)                  0               ['tf.math.multiply_20[0][0]',                  \n",
            "                                                                                              'tf.compat.v1.transpose_7[0][0]']             \n",
            "                                                                                                                                            \n",
            "============================================================================================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________________________________________________\n",
            "\n",
            "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
            "\u001b[32msaved_model output complete!\u001b[0m\n",
            "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n",
            "Estimated count of arithmetic ops: 33.783 G  ops, equivalently 16.892 G  MACs\n",
            "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
            "Estimated count of arithmetic ops: 33.783 G  ops, equivalently 16.892 G  MACs\n",
            "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TFLite model and see some details about input/output\n",
        "import tensorflow as tf\n",
        "tflite_interpreter = tf.lite.Interpreter(model_path='/content/YOLOv6/saved_model/yolov6m_float16.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmOfoqqBDQMi",
        "outputId": "a772ffe5-c655-466b-9662-96e2542966ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Input details ==\n",
            "name: inputs_0\n",
            "shape: [  1 480 640   3]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "name: Identity\n",
            "shape: [   1 6300   14]\n",
            "type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TFLite model and see some details about input/output\n",
        "import tensorflow as tf\n",
        "tflite_interpreter = tf.lite.Interpreter(model_path='/content/YOLOv6/saved_model/yolov6m_float32.tflite')\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83IQ0JaXFn3V",
        "outputId": "de9199a0-f75f-4e19-945f-9321429fb13b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Input details ==\n",
            "name: inputs_0\n",
            "shape: [  1 480 640   3]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "name: Identity\n",
            "shape: [   1 6300   14]\n",
            "type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "#print(\"Hub version: \", hub.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYLWNaloGift",
        "outputId": "57253dea-6a7d-4a5a-8db4-bb7af2bce9ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-f613a4bc459a>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.10.0\n",
            "Eager mode:  True\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BO5RfjipHD1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}